{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "109de5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "from time import time, sleep\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "from conf import conf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c7b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5a50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME='classifierdl_use_emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34daba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumerConf = {'bootstrap.servers': conf.BOOTSTRAP_SERVER,\n",
    "        'group.id': \"AfekaFinalProj\",\n",
    "        'auto.offset.reset': 'smallest'}\n",
    "\n",
    "consumer = Consumer(consumerConf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "\n",
    "sentimentdl = ClassifierDLModel.pretrained(name=MODEL_NAME)\\\n",
    "    .setInputCols([\"sentence_embeddings\"])\\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          use,\n",
    "          sentimentdl\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a8683",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "pipelineModel = nlpPipeline.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b652709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCategory(sentiment):\n",
    "  negList = ['fear', 'sadness']\n",
    "  if sentiment in negList:\n",
    "    return 'Negative'\n",
    "  else:\n",
    "    return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672e6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "running = True\n",
    "\n",
    "def basic_consume_loop(consumer, topics):\n",
    "    try:        \n",
    "        consumer.subscribe(topics)\n",
    "        \n",
    "        start_time = time()\n",
    "        seconds = 2\n",
    "\n",
    "        batch = []\n",
    "        \n",
    "        while running:         \n",
    "            msg = consumer.poll(timeout=3.0)            \n",
    "            \n",
    "            current_time = time()\n",
    "            elapsed_time = current_time - start_time\n",
    "    \n",
    "            # create a new file\n",
    "            if elapsed_time > seconds:               \n",
    "                \n",
    "                if len(batch) > 0:      \n",
    "\n",
    "                    df = spark.createDataFrame(pd.DataFrame({\"text\":batch}))\n",
    "                    result = pipelineModel.transform(df) \n",
    "                    \n",
    "                    sentimentDF = result.select(F.explode('sentiment.result')).toPandas()\n",
    "\n",
    "                    sentimentDF['PosNeg'] = sentimentDF['col'].apply(toCategory)\n",
    "\n",
    "                    sentimentDF.groupby('PosNeg')[\"PosNeg\"].count().plot(kind=\"pie\")\n",
    "\n",
    "                    sentimentDF.groupby('PosNeg')[\"PosNeg\"].count().plot(kind=\"bar\")\n",
    "\n",
    "                    \n",
    "                    batch = []\n",
    "                \n",
    "                start_time = time()  \n",
    "                \n",
    "            if msg is None: continue\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition event\n",
    "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
    "                                     (msg.topic(), msg.partition(), msg.offset()))\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                batch.append(msg.value().decode('utf-8'))\n",
    "                \n",
    "    finally:\n",
    "        # Close down consumer to commit final offsets.\n",
    "        consumer.close()\n",
    "\n",
    "def shutdown():\n",
    "    running = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02831eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_consume_loop(consumer, [conf.KAFKA_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef717dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
